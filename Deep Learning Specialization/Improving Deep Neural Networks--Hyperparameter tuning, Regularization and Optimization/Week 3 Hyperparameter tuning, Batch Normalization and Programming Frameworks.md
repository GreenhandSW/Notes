# 1. 调试处理

重要性：$\alpha$>$\beta$, hidden units, learning rate decay>layers, mini-batch size>$\beta_1, \beta_2, \epsilon$。

寻找超参数最佳取值的常用方法：

1. 随机取值：由于超参数较多时，各超参数相对重要性未知，因此一般不能进行网格化取值，而应该随机取值。

2. 精细搜索：若某个范围内表现较好，则可放大该区域，即对该区域进行更密集的取值

# 2. 为超参数选择合适的范围

| 超参数   | 尺度                                                         |
| -------- | ------------------------------------------------------------ |
| 网络层数 | 层数分布较为均匀，因此采用**均匀取值**                       |
| $\alpha$ | 需要在某一值附近取较多的值，因此采用**对数取值**             |
| $\beta$  | 由于$\frac 1 {1-\beta}$必须为整数，且需要在$1$的附近取较多的值，因此采用对数取值 |

# 3. 超参数训练的实践： Pandas VS Caviar

调参流派：

1. Babysitting one model：（用于训练资源不足时）运行一个模型，随着时间推移，观察模型表现，并实时调整参数
2. Traning many models in parallel： （用于训练资源充足时）同时运行多个模型，根据结果选择表现最好的模型

# 4. 正则化网络的激活函数

将$a^{[l]}$（实际上是$z^{[l]}$）进行归一化

> given some intermediate values in NN